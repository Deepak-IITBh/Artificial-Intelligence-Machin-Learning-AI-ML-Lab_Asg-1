{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Aa-nRCzPVdF"
      },
      "source": [
        "# Create a Multilingual Speech Translation\n",
        "\n",
        "Here we are going to create a multilingual text translation using IndicTrans2 models which were originally trained with the fairseq to HuggingFace transformers for inference purpose.\n",
        "\n",
        "IndicTrans2 is a Transformer made by Voluteers for AI4Bharat which can translate 22 languages in India.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cfsv02IeP2It"
      },
      "source": [
        "## Necessary Step\n",
        "\n",
        "Please run the cells below to install the necessary dependencies.\n",
        "\n",
        "<font color='red'>DO NOT CHNAGE ANY CODE GIVEN BELOW</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ViXRCnCggoS1"
      },
      "outputs": [],
      "source": [
        "!export CUDA_LAUNCH_BLOCKING=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qKcYlUZYGLrt"
      },
      "outputs": [],
      "source": [
        "# Clone the required Git repository for IndicTrans2\n",
        "%%capture\n",
        "!git clone https://github.com/AI4Bharat/IndicTrans2.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U3vs7FkIGSxK"
      },
      "outputs": [],
      "source": [
        "# Clone the Hugging face interface from github\n",
        "%%capture\n",
        "%cd /content/IndicTrans2/huggingface_interface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ddkRAXQ2Git0"
      },
      "outputs": [],
      "source": [
        "# Install other essential dependecies for working of the transformer\n",
        "%%capture\n",
        "!python3 -m pip install nltk sacremoses pandas regex mock transformers>=4.33.2 mosestokenizer\n",
        "!python3 -c \"import nltk; nltk.download('punkt')\"\n",
        "!python3 -m pip install bitsandbytes scipy accelerate datasets\n",
        "!python3 -m pip install sentencepiece\n",
        "\n",
        "!git clone https://github.com/VarunGumma/IndicTransTokenizer\n",
        "%cd IndicTransTokenizer\n",
        "!python3 -m pip install --editable ./\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hjN7ub1tO33H"
      },
      "source": [
        "**IMPORTANT : Restart your run-time first and then run the cells below.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SLBIw6rQB-0"
      },
      "source": [
        "## Working for Transformer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GNM92xDow72u"
      },
      "source": [
        "1. Import the followings that you have installed in the previous section:\n",
        "  * transformer\n",
        "  * torch\n",
        "  * AutoModelForSeq2SeqLM from transformer\n",
        "  * BitsAndBytesConfig from transformer\n",
        "  * IndicProcessor from from IndicTransTokenizer\n",
        "  * IndicTransTokenizer from IndicTransTokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IRfv0xszaQfx"
      },
      "outputs": [],
      "source": [
        "# import essentials\n",
        "import transformers\n",
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from IndicTransTokenizer import IndicTransTokenizer\n",
        "from IndicTransTokenizer import IndicProcessor\n",
        "from transformers import AutoModelForSeq2SeqLM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "12Dh_PiMzBsd"
      },
      "source": [
        "2. Set the Batch size equal to 4. Then create a variable DEVICE and set it to \"cuda\" if torch.cuda.is_available() or else set it as \"cpu\". Finally set Quantization as \"None\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fYczM2U6G1Zv"
      },
      "outputs": [],
      "source": [
        "# Set the variables\n",
        "BATCH_SIZE = 4\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "QUANTIZATION = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLl9glW7zfjM"
      },
      "source": [
        "3. We are going to create Two functions.\n",
        "    * Create a function to intialise the model and the tokenizer and returns both\n",
        "    * Create another function which will help in the translation of a whole batch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLnr2RfM0QTt"
      },
      "source": [
        "### Creating the model initializer and tokenizer function.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yIC98HYa0XRN"
      },
      "source": [
        "Create a function initialize_model_and_tokenizer which takes in 4 arguments: ckpt_dir, direction, quantization.\n",
        "Inside the function, if quantization  = '4-bit' then create a variable qconfig and use appropriate BitsAndByteConfig to instantiate it. Else if quantization  = '8-bit', then do the necessary. Else, set it to None.\n",
        "\n",
        "(For more read the following documentation on [BitsAndByteConfig](https://huggingface.co/docs/transformers/en/main_classes/quantization#transformers.BitsAndBytesConfig).)\n",
        "\n",
        "After the conditional flow, create a variable tokenizer\n",
        "\n",
        "Next step will be to create a model variable set to AutoModelForSeq2SeqLM where we have to load the pretrained model from checkpoint directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xj1WCNjuHG-d"
      },
      "outputs": [],
      "source": [
        "# Create a function initialize_model_and_tokenizer which takes in 4 arguments: ckpt_dir, direction, quantization.\n",
        "\n",
        "def initialize_model_and_tokenizer(ckpt_dir, direction, quantization):\n",
        "    # if quantization  = '4-bit'\n",
        "    if quantization == '4-bit':\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_4bit=True,\n",
        "            bnb_4bit_use_double_quant=True,\n",
        "            bnb_4bit_compute_dtype=torch.bfloat16\n",
        "        )\n",
        "    # Else if quantization  = '8-bit'\n",
        "    elif quantization == '8-bit':\n",
        "        qconfig = BitsAndBytesConfig(\n",
        "            load_in_8bit=True,\n",
        "            bnb_8bit_use_double_quant=True,\n",
        "            bnb_8bit_compute_dtype=torch.bfloat16\n",
        "        )\n",
        "    # Else, set it to None.\n",
        "    else:\n",
        "        qconfig = None\n",
        "\n",
        "    # Create a variable tokenizer and set it as IndicTransTokenizer with direction set as direction.\n",
        "\n",
        "    tokenizer = IndicTransTokenizer(direction=direction)\n",
        "\n",
        "\n",
        "    # Create a model variable set to AutoModelForSeq2SeqLM\n",
        "    # Keep trust_remote_code=True, low_cpu_mem_usage=True and quantization_config=qconfig.\n",
        "\n",
        "    model = AutoModelForSeq2SeqLM.from_pretrained(ckpt_dir, trust_remote_code=True, low_cpu_mem_usage=True, quantization_config=qconfig)\n",
        "    return tokenizer, model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # if qconfig is none, save the model in device.\n",
        "    if qconfig == None:\n",
        "        model = model.to(DEVICE)\n",
        "        if DEVICE == \"cuda\":\n",
        "            model.half()\n",
        "\n",
        "    # Evaluate the model\n",
        "    model.eval()\n",
        "\n",
        "\n",
        "    # return both tokenizer and model\n",
        "    return tokenizer, model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCWrirPAF3aM"
      },
      "source": [
        "### Helper Function to get translation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nPlUvJN1CX0K"
      },
      "outputs": [],
      "source": [
        "def batch_translate(input_sentences, src_lang, tgt_lang, model, tokenizer, ip):\n",
        "    translations = []\n",
        "    for i in range(0, len(input_sentences), BATCH_SIZE):\n",
        "        batch = input_sentences[i : i + BATCH_SIZE]\n",
        "\n",
        "        # Preprocess the batch and extract entity mappings\n",
        "        batch = ip.preprocess_batch(batch, src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "\n",
        "        # Tokenize the batch and generate input encodings\n",
        "        inputs = tokenizer(\n",
        "            batch,\n",
        "            src=True,\n",
        "            truncation=True,\n",
        "            padding=\"longest\",\n",
        "            return_tensors=\"pt\",\n",
        "            return_attention_mask=True,\n",
        "        ).to(DEVICE)\n",
        "\n",
        "        # Generate translations using the model\n",
        "        with torch.no_grad():\n",
        "            generated_tokens = model.generate(\n",
        "                **inputs,\n",
        "                use_cache=True,\n",
        "                min_length=0,\n",
        "                max_length=256,\n",
        "                num_beams=5,\n",
        "                num_return_sequences=1,\n",
        "            )\n",
        "\n",
        "        # Decode the generated tokens into text\n",
        "        generated_tokens = tokenizer.batch_decode(generated_tokens.detach().cpu().tolist(), src=False)\n",
        "\n",
        "        # Postprocess the translations, including entity replacement\n",
        "        translations += ip.postprocess_batch(generated_tokens, lang=tgt_lang)\n",
        "\n",
        "        del inputs\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    return translations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erNCuZTEMt49"
      },
      "source": [
        "### English to Indic Example\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4DHmACMxGXCD"
      },
      "source": [
        "Provided below are some example sentences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uk6qXv_fGCxa"
      },
      "outputs": [],
      "source": [
        "# sample sentences\n",
        "en_sents = [\n",
        "    \"Akshat is very bad boy.\",\n",
        "    \"When I was young, I used to go to the park every day.\",\n",
        "    \"He has many old books, which he inherited from his ancestors.\",\n",
        "    \"I can't figure out how to solve my problem.\",\n",
        "    \"She is very hardworking and intelligent, which is why she got all the good marks.\",\n",
        "    \"We watched a new movie last week, which was very inspiring.\",\n",
        "    \"If you had met me at that time, we would have gone out to eat.\",\n",
        "    \"She went to the market with her sister to buy a new sari.\",\n",
        "    \"Raj told me that he is going to his grandmother's house next month.\",\n",
        "    \"All the kids were having fun at the party and were eating lots of sweets.\",\n",
        "    \"My friend has invited me to his birthday party, and I will give him a gift.\",\n",
        "]\n",
        "\n",
        "hi_sents = [\n",
        "    \"जब मैं छोटा था, मैं हर रोज़ पार्क जाता था।\",\n",
        "    \"उसके पास बहुत सारी पुरानी किताबें हैं, जिन्हें उसने अपने दादा-परदादा से विरासत में पाया।\",\n",
        "    \"मुझे समझ में नहीं आ रहा कि मैं अपनी समस्या का समाधान कैसे ढूंढूं।\",\n",
        "    \"वह बहुत मेहनती और समझदार है, इसलिए उसे सभी अच्छे मार्क्स मिले।\",\n",
        "    \"हमने पिछले सप्ताह एक नई फिल्म देखी जो कि बहुत प्रेरणादायक थी।\",\n",
        "    \"अगर तुम मुझे उस समय पास मिलते, तो हम बाहर खाना खाने चलते।\",\n",
        "    \"वह अपनी दीदी के साथ बाजार गयी थी ताकि वह नई साड़ी खरीद सके।\",\n",
        "    \"राज ने मुझसे कहा कि वह अगले महीने अपनी नानी के घर जा रहा है।\",\n",
        "    \"सभी बच्चे पार्टी में मज़ा कर रहे थे और खूब सारी मिठाइयाँ खा रहे थे।\",\n",
        "    \"मेरे मित्र ने मुझे उसके जन्मदिन की पार्टी में बुलाया है, और मैं उसे एक तोहफा दूंगा।\",\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X644TodGGkBE"
      },
      "source": [
        "Now we have to Finally join all the functions and datasets together to create our own predictions.\n",
        "\n",
        "Here is the list of languages supported by the IndicTrans2 models:\n",
        "\n",
        "| Language                       | Code      | Language                        | Code      | Language                       | Code      |\n",
        "|--------------------------------|-----------|---------------------------------|-----------|--------------------------------|-----------|\n",
        "| Assamese                       | asm_Beng  | Kashmiri (Arabic)               | kas_Arab  | Punjabi                        | pan_Guru  |\n",
        "| Bengali                        | ben_Beng  | Kashmiri (Devanagari)           | kas_Deva  | Sanskrit                       | san_Deva  |\n",
        "| Bodo                           | brx_Deva  | Maithili                        | mai_Deva  | Santali                        | sat_Olck  |\n",
        "| Dogri                          | doi_Deva  | Malayalam                       | mal_Mlym  | Sindhi (Arabic)                | snd_Arab  |\n",
        "| English                        | eng_Latn  | Marathi                         | mar_Deva  | Sindhi (Devanagari)            | snd_Deva  |\n",
        "| Konkani                        | gom_Deva  | Manipuri (Bengali)              | mni_Beng  | Tamil                          | tam_Taml  |\n",
        "| Gujarati                       | guj_Gujr  | Manipuri (Meitei)               | mni_Mtei  | Telugu                         | tel_Telu  |\n",
        "| Hindi                          | hin_Deva  | Nepali                          | npi_Deva  | Urdu                           | urd_Arab  |\n",
        "| Kannada                        | kan_Knda  | Odia                            | ory_Orya  |                                |           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAAIOoiM7mCg"
      },
      "source": [
        "# en to telugu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6OG3Bw-sHnf3",
        "outputId": "30bf8580-8bfc-4a40-95c8-8275d220c267"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "<ipython-input-3-5448b56d8da9>:24: DeprecationWarning: This IndicTransTokenizer is deprecated.\n",
            "The official Tokenizer is available on HF and can be used as follows:\n",
            "```\n",
            "from transformers import AutoTokenizer\n",
            "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
            "```\n",
            "  tokenizer = IndicTransTokenizer(direction=direction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng_Latn-tel_Telu\n",
            "eng_Latn My name is Deepak.\n",
            "tel_Telu నా పేరు దీపక్.\n",
            "\n",
            "eng_Latn I am pursuing a BTech degree in Data Science and AI from IIT Bhilai.\n",
            "tel_Telu నేను ఐఐటి భిలాయ్ నుండి డేటా సైన్స్ మరియు ఎఐలో బిటెక్ డిగ్రీ చదువుతున్నాను.\n",
            "\n",
            "eng_Latn Currently, I am in my pre-final year.\n",
            "tel_Telu ప్రస్తుతం, నేను నా ప్రీ-ఫైనల్ సంవత్సరంలో ఉన్నాను.\n",
            "\n",
            "eng_Latn I am passionate about machine learning and artificial intelligence.\n",
            "tel_Telu నాకు మెషిన్ లెర్నింగ్ మరియు ఆర్టిఫిషియల్ ఇంటెలిజెన్స్ పట్ల మక్కువ ఉంది.\n",
            "\n",
            "eng_Latn In my free time, I enjoy coding and working on various data science projects.\n",
            "tel_Telu నా ఖాళీ సమయంలో, నేను కోడింగ్ మరియు వివిధ డేటా సైన్స్ ప్రాజెక్టులలో పనిచేయడం ఆనందిస్తాను.\n",
            "\n",
            "eng_Latn I have experience with programming languages like C++, Python, and SQL.\n",
            "tel_Telu నాకు సి + +, పైథాన్ మరియు ఎస్ క్యూ ఎల్ వంటి ప్రోగ్రామింగ్ భాషలలో అనుభవం ఉంది.\n",
            "\n",
            "eng_Latn I am skilled in using frameworks such as Spring Boot and tools for natural language processing.\n",
            "tel_Telu స్ప్రింగ్ బూట్ వంటి ఫ్రేమ్వర్క్లు మరియు సహజ భాషా ప్రాసెసింగ్ కోసం సాధనాలను ఉపయోగించడంలో నాకు నైపుణ్యం ఉంది.\n",
            "\n",
            "eng_Latn My goal is to gain experience through internships and contribute to innovative projects in the field of AI.\n",
            "tel_Telu ఇంటర్న్షిప్ల ద్వారా అనుభవాన్ని పొందడం, ఏఐ రంగంలో వినూత్న ప్రాజెక్టులకు తోడ్పడటం నా లక్ష్యం.\n",
            "\n",
            "eng_Latn I actively participate in discussions related to software engineering and data science.\n",
            "tel_Telu సాఫ్ట్వేర్ ఇంజనీరింగ్ మరియు డేటా సైన్స్కు సంబంధించిన చర్చలలో నేను చురుకుగా పాల్గొంటాను.\n",
            "\n",
            "eng_Latn Outside of academics, I like to explore new technologies and stay updated with industry trends.\n",
            "tel_Telu విద్యావేత్తల వెలుపల, నేను కొత్త సాంకేతిక పరిజ్ఞానాన్ని అన్వేషించడానికి మరియు పరిశ్రమ పోకడలకు అనుగుణంగా ఉండటానికి ఇష్టపడతాను.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a variable to store \"ai4bharat/indictrans2-en-indic-1B\" as checkpoint directory\n",
        "ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"\n",
        "\n",
        "\n",
        "\n",
        "# get the tokenizer and model by passing essential arguments to initialize_model_and_tokenizer function\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(ckpt_dir, direction=\"en-indic\", quantization='8-bit')\n",
        "\n",
        "\n",
        "# instantiate IndicProcessor with inference = True\n",
        "en_indic_ip = IndicProcessor(inference=True)\n",
        "\n",
        "\n",
        "\n",
        "# Choose the source langauge as English and target language as Hindi.\n",
        "src_lang = \"eng_Latn\"\n",
        "tgt_lang = \"tel_Telu\"\n",
        "# src_lang = \"hin_Deva\"\n",
        "# tgt_lang = \"eng_Latn\"\n",
        "\n",
        "\n",
        "input_sents = [\n",
        "    \"My name is Deepak.\",\n",
        "    \"I am pursuing a BTech degree in Data Science and AI from IIT Bhilai.\",\n",
        "    \"Currently, I am in my pre-final year.\",\n",
        "    \"I am passionate about machine learning and artificial intelligence.\",\n",
        "    \"In my free time, I enjoy coding and working on various data science projects.\",\n",
        "    \"I have experience with programming languages like C++, Python, and SQL.\",\n",
        "    \"I am skilled in using frameworks such as Spring Boot and tools for natural language processing.\",\n",
        "    \"My goal is to gain experience through internships and contribute to innovative projects in the field of AI.\",\n",
        "    \"I actively participate in discussions related to software engineering and data science.\",\n",
        "    \"Outside of academics, I like to explore new technologies and stay updated with industry trends.\",\n",
        "]\n",
        "\n",
        "\n",
        "# Find target translation using the batch_translate function\n",
        "la_pred = batch_translate(input_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, en_indic_ip)\n",
        "\n",
        "\n",
        "print(f\"{src_lang}-{tgt_lang}\")\n",
        "# Print input sentence and its translation.\n",
        "for i in range(len(input_sents)):\n",
        "    print(f\"{src_lang} {input_sents[i]}\")\n",
        "    print(f\"{tgt_lang} {la_pred[i]}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "del en_indic_tokenizer, en_indic_model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##English to Maithili"
      ],
      "metadata": {
        "id": "eF8V45yLN2qy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a variable to store \"ai4bharat/indictrans2-en-indic-1B\" as checkpoint directory\n",
        "ckpt_dir = \"ai4bharat/indictrans2-en-indic-1B\"\n",
        "\n",
        "\n",
        "\n",
        "# get the tokenizer and model by passing essential arguments to initialize_model_and_tokenizer function\n",
        "en_indic_tokenizer, en_indic_model = initialize_model_and_tokenizer(ckpt_dir, direction=\"en-indic\", quantization='8-bit')\n",
        "\n",
        "\n",
        "# instantiate IndicProcessor with inference = True\n",
        "en_indic_ip = IndicProcessor(inference=True)\n",
        "\n",
        "\n",
        "\n",
        "# Choose the source langauge as English and target language as Hindi.\n",
        "src_lang = \"eng_Latn\"\n",
        "tgt_lang = \"mai_Deva\"\n",
        "# src_lang = \"hin_Deva\"\n",
        "# tgt_lang = \"eng_Latn\"\n",
        "\n",
        "\n",
        "input_sents = [\n",
        "    \"My name is Deepak.\",\n",
        "    \"I am pursuing a BTech degree in Data Science and AI from IIT Bhilai.\",\n",
        "    \"Currently, I am in my pre-final year.\",\n",
        "    \"I am passionate about machine learning and artificial intelligence.\",\n",
        "    \"In my free time, I enjoy coding and working on various data science projects.\",\n",
        "    \"I have experience with programming languages like C++, Python, and SQL.\",\n",
        "    \"I am skilled in using frameworks such as Spring Boot and tools for natural language processing.\",\n",
        "    \"My goal is to gain experience through internships and contribute to innovative projects in the field of AI.\",\n",
        "    \"I actively participate in discussions related to software engineering and data science.\",\n",
        "    \"Outside of academics, I like to explore new technologies and stay updated with industry trends.\",\n",
        "]\n",
        "\n",
        "# Find target translation using the batch_translate function\n",
        "la_pred = batch_translate(input_sents, src_lang, tgt_lang, en_indic_model, en_indic_tokenizer, en_indic_ip)\n",
        "\n",
        "\n",
        "print(f\"{src_lang}-{tgt_lang}\")\n",
        "# Print input sentence and its translation.\n",
        "for i in range(len(input_sents)):\n",
        "    print(f\"{src_lang} {input_sents[i]}\")\n",
        "    print(f\"{tgt_lang}maithili predicted langugae:{la_pred[i]}\")\n",
        "    print()\n",
        "\n",
        "\n",
        "# flush the models to free the GPU memory\n",
        "del en_indic_tokenizer, en_indic_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9JtFLfo-NG1M",
        "outputId": "2559224c-b24d-4ef0-9a22-6b61500629d4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['bnb_8bit_use_double_quant', 'bnb_8bit_compute_dtype']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n",
            "<ipython-input-3-5448b56d8da9>:24: DeprecationWarning: This IndicTransTokenizer is deprecated.\n",
            "The official Tokenizer is available on HF and can be used as follows:\n",
            "```\n",
            "from transformers import AutoTokenizer\n",
            "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
            "```\n",
            "  tokenizer = IndicTransTokenizer(direction=direction)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "eng_Latn-mai_Deva\n",
            "eng_Latn My name is Deepak.\n",
            "mai_Devamaithili predicted langugae:हमर नाम दीपक अछि।\n",
            "\n",
            "eng_Latn I am pursuing a BTech degree in Data Science and AI from IIT Bhilai.\n",
            "mai_Devamaithili predicted langugae:हम आई. आई. टी. भिलाई सँ डेटा साइंस आ ए. आई. मे बी. टेक डिग्री प्राप्त कऽ रहल छी।\n",
            "\n",
            "eng_Latn Currently, I am in my pre-final year.\n",
            "mai_Devamaithili predicted langugae:वर्तमान मे हम अपन प्री-फाइनल ईयर मे छी।\n",
            "\n",
            "eng_Latn I am passionate about machine learning and artificial intelligence.\n",
            "mai_Devamaithili predicted langugae:हम मशीन लर्निंग आ आर्टिफिशियल इंटेलिजेंस के बारे में भावुक छी।\n",
            "\n",
            "eng_Latn In my free time, I enjoy coding and working on various data science projects.\n",
            "mai_Devamaithili predicted langugae:खाली समय मे हमरा कोडिंग आ विभिन्न डेटा विज्ञान परियोजना पर काज करबामे मजा अबैत अछि।\n",
            "\n",
            "eng_Latn I have experience with programming languages like C++, Python, and SQL.\n",
            "mai_Devamaithili predicted langugae:हमरा सी + +, पायथन, आ एसक्यूएल सन प्रोग्रामिंग भाषाक अनुभव अछि।\n",
            "\n",
            "eng_Latn I am skilled in using frameworks such as Spring Boot and tools for natural language processing.\n",
            "mai_Devamaithili predicted langugae:हम स्प्रिंग बूट आ प्राकृतिक भाषा प्रक्रियाक लेल उपकरण सन ढाँचाक उपयोग करबामे कुशल छी।\n",
            "\n",
            "eng_Latn My goal is to gain experience through internships and contribute to innovative projects in the field of AI.\n",
            "mai_Devamaithili predicted langugae:हमर लक्ष्य इंटर्नशिपक माध्यमसँ अनुभव प्राप्त करब आ ए. आई. क क्षेत्रमे नवप्रवर्तनशील परियोजनामे योगदान देबऽ अछि।\n",
            "\n",
            "eng_Latn I actively participate in discussions related to software engineering and data science.\n",
            "mai_Devamaithili predicted langugae:हम सॉफ्टवेयर इंजीनियरिंग आ डेटा विज्ञानसँ सम्बन्धित चर्चा सभमे सक्रिय रूपसँ भाग लैत छी।\n",
            "\n",
            "eng_Latn Outside of academics, I like to explore new technologies and stay updated with industry trends.\n",
            "mai_Devamaithili predicted langugae:शिक्षाविदों के अलावा, हम नव तकनीक के खोज केनाइ पसंद करैत छी आ उद्योग के रुझान सँ अपडेट रहब पसंद करैत छी।\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6AzM1bH29NN3"
      },
      "source": [
        "***"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KxURebbfOrlW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}